{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import modules for CarbonIface\n",
    "import socket, pickle, struct, urllib2\n",
    "\n",
    "#import general modules\n",
    "import threading\n",
    "import io, os.path, time, math, threading, sys, random\n",
    "import ConfigParser, ast\n",
    "\n",
    "#custom consumer and carbon/graphite-interface modules\n",
    "import avro.schema, avro.io\n",
    "from carboniface import CarbonIface\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "#data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sc_watchdog.logger import log\n",
    "class CarbonIface(object):\n",
    "    \n",
    "    def __init__(self, host, port, event_url = 'events'):\n",
    "        '''Initialize Carbon Interface. \n",
    "        host: host where the carbon daemon is running\n",
    "        port: port where carbon daemon is listening for pickle protocol on host\n",
    "        event_url: web app url suffix where events can be added. It must be provided if add_event(...) is to \n",
    "                   be used. Otherwise an exception by urllib2 will raise\n",
    "        '''\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.url_post_event = \"http://%s/%s/\" % (host, event_url)\n",
    "        self.__data = []\n",
    "        self.__data_lock = threading.Lock()\n",
    "        \n",
    "    def add_data(self, metric, value, ts=None):\n",
    "        if not ts:\n",
    "            ts = time.time()\n",
    "        if self.__data_lock.acquire():\n",
    "            self.__data.append((metric, (ts, value)))\n",
    "            self.__data_lock.release()\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def add_data_dict(self, dd):\n",
    "        '''\n",
    "        dd must be a dictionary where keys are the metric name, \n",
    "        each key contains a dictionary which at least must have 'value' key (optionally 'ts')\n",
    "        \n",
    "        dd = {'experiment1.subsystem.block.metric1': {'value': 12.3, 'ts': 1379491605.55},\n",
    "              'experiment1.subsystem.block.metric2': {'value': 1.35},\n",
    "             ...}\n",
    "        '''\n",
    "        if self.__data_lock.acquire():\n",
    "            for k,v in dd.items():\n",
    "                ts = v.get('ts', time.time())\n",
    "                value = v.get('value')\n",
    "                self.__data.append((k, (ts, value)))\n",
    "            self.__data_lock.release()\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def add_data_list(self, dl):\n",
    "        '''\n",
    "        dl must be a list of tuples like:\n",
    "        dl = [('metricname', (timestamp, value)),\n",
    "              ('metricname', (timestamp, value)),\n",
    "              ...]\n",
    "        '''\n",
    "        if self.__data_lock.acquire():\n",
    "            self.__data.extend(dl)\n",
    "            self.__data_lock.release()\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def send_data(self, data=None):\n",
    "        '''If data is empty, current buffer is sent. Otherwise data must be like:\n",
    "        data = [('metricname', (timestamp, value)),\n",
    "              ('metricname', (timestamp, value)),\n",
    "              ...]\n",
    "        '''\n",
    "        save_in_error = False\n",
    "        if not data:\n",
    "            if self.__data_lock.acquire():\n",
    "                data = self.__data\n",
    "                self.__data = []\n",
    "                save_in_error = True\n",
    "                self.__data_lock.release()\n",
    "            else:\n",
    "                return False\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        payload = pickle.dumps(data)\n",
    "        header = struct.pack(\"!L\", len(payload))\n",
    "        message = header + payload\n",
    "        s.connect((self.host, self.port))\n",
    "        try:\n",
    "            s.send(message)\n",
    "        except:\n",
    "            #log.exception('Error when sending data to carbon')\n",
    "            if save_in_error:\n",
    "                self.__data.extend(data)\n",
    "            return False\n",
    "        else:\n",
    "            #log.debug('Sent data to {host}:{port}: {0} metrics, {1} bytes'.format(len(data), len(message), host = self.host, port=self.port))\n",
    "            return True\n",
    "        finally:\n",
    "            s.close()\n",
    "        \n",
    "    def add_event(self, what, data=None, tags=None, when=None):\n",
    "        if not when: when = time.time()\n",
    "        postdata = '{{\"what\":\"{0}\", \"when\":{1}'.format(what, when)\n",
    "        if data: postdata += ', \"data\":\"{0}\"'.format(str(data))\n",
    "        if tags: postdata += ', \"tags\": \"{0}\"'.format(str(tags))\n",
    "        postdata += '}'\n",
    "        req = urllib2.Request(self.url_post_event)\n",
    "        req.add_data(postdata)\n",
    "        \n",
    "        try:\n",
    "            urllib2.urlopen(req)\n",
    "        except Exception, _:\n",
    "            #log.exception('Error when sending event to carbon')\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from MR, SVDS\n",
    "class PythonConsumerThread(object):\n",
    "    \"\"\" Threading example class\n",
    "    The run() method will be started and it will run in the background\n",
    "    until the application exits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,flag):\n",
    "        self.cancelled = False\n",
    "        self.read_config()\n",
    "        self.carboniface_loader()\n",
    "        self.flag = flag\n",
    "        #instantiate variables for spreading out graphite messages\n",
    "        self.last_send_time=time.time()\n",
    "        self.data=[]\n",
    "        #for analyzing in python\n",
    "        #self.setup_history()\n",
    "        self.msg_num=0\n",
    "        #spin up the thread\n",
    "        thread = threading.Thread(target=self.run, args=())\n",
    "        thread.daemon = True                            # Daemonize thread\n",
    "        thread.start()                                  # Start the execution\n",
    "        print self, 'created'\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\" Method that runs forever \"\"\"\n",
    "        while not self.cancelled:\n",
    "            self.consume_messages()\n",
    "            #self.consume_messages_synthetic()\n",
    "            #time.sleep(1/self.fps)\n",
    "        else: \n",
    "            print 'Consumer Thread Terminated'\n",
    "    \n",
    "    def cancel(self):\n",
    "        \"\"\"End this timer thread\"\"\"\n",
    "        self.cancelled = True\n",
    "    \n",
    "    def read_config(self):\n",
    "        config_directory=(os.path.abspath(os.path.join(os.path.dirname(''), '..', 'conf')) + '/')\n",
    "        config = ConfigParser.RawConfigParser()\n",
    "        config_file='rpi_consumer.cfg'\n",
    "        config.read(config_directory+config_file)\n",
    "        self.host = str(config.get('MSG','host'))\n",
    "        self.port = int(config.get('MSG','port'))\n",
    "        self.event_url = str(config.get('MSG','event_url'))\n",
    "        self.topic=str(config.get('MSG','topic'))\n",
    "        self.input_kafka_topic=str(config.get('MSG','input_kafka_topic'))\n",
    "        self.bootstrap_servers=ast.literal_eval(config.get('MSG','bootstrap_servers'))\n",
    "        self.group_id=str(config.get('MSG','group_id'))\n",
    "        self.fps=float(config.get('MSG','fps'))\n",
    "        #get schema for csv\n",
    "        self.channel_schema=ast.literal_eval(config.get('MSG','channel_schema'))\n",
    "        self.msg_per_sec=float(config.get('MSG','msg_per_sec'))\n",
    "        print 'schema:', self.channel_schema\n",
    "\n",
    "    def carboniface_loader(self):\n",
    "        #information for carbon interface class\n",
    "        self.data = []\n",
    "        self.carbon = CarbonIface(host=self.host, port=self.port, event_url=self.event_url)\n",
    "        print self.carbon,'created'\n",
    "        \n",
    "    def add_consumer_message_to_carbon_queue(self,datum,topic):\n",
    "        #find channel name and add it to the general topic\n",
    "        topic += '.'+str((datum[0])) \n",
    "        #assume the time is the last entry in the schema\n",
    "        timestamp=(datum[-1])\n",
    "        #print timestamp, (time.time())\n",
    "        for i in range(1,len(datum)-1):\n",
    "            #make the topic longer using the known schema information\n",
    "            topic_specific=topic + '.'+str(self.channel_schema[i]) \n",
    "            #append the data in the following format (topic, (time, value)), the time,value need to be a tuple\n",
    "            self.data.append((topic_specific,(timestamp,datum[i])))\n",
    "        \n",
    "    def create_artificial_message(self):\n",
    "        #AF3 (left frontal), AF4 (right frontal), T7 (left temporal), T8 (right temporal), and Pz (central parietal).sensor_array=['AF3','AF4','T7','T8','Pz']\n",
    "        sensor=random.choice(sensor_array)\n",
    "        Theta=1410.735220 * random.uniform(0.5, 1.5)\n",
    "        Alpha=1821.903537 * random.uniform(0.8, 1.2)\n",
    "        Low_beta=1125.776789 * random.uniform(0.2, 1.8)\n",
    "        High_beta=1823.893874 * random.uniform(0.6, 1.4)\n",
    "        Gamma=346.522470 * random.uniform(0.9, 1.1)\n",
    "        Time=time.time()\n",
    "        self.msg=[sensor,Theta,Alpha,Low_beta,High_beta,Gamma,Time]\n",
    "        #print self.msg\n",
    "    \n",
    "    def consume_messages_synthetic(self):\n",
    "        print 'consuming synthetic messages'\n",
    "        while self.cancelled!=True:\n",
    "            self.create_artificial_message()\n",
    "            self.decode_message(self.msg)\n",
    "            time.sleep(1.0/self.msg_per_sec)\n",
    "        \n",
    "    def consume_messages(self):\n",
    "        #from:https://gist.github.com/ChristianKniep/9580204\n",
    "        print 'self.input_kafka_topic',self.input_kafka_topic\n",
    "        print 'self.group_id',self.group_id\n",
    "        print 'self.bootstrap_servers',self.bootstrap_servers\n",
    "        consumer = KafkaConsumer(self.input_kafka_topic,\n",
    "                                 group_id=self.group_id,\n",
    "                                 bootstrap_servers=self.bootstrap_servers)\n",
    "        #print consumer.topics()\n",
    "        print consumer, 'connected'\n",
    "        self.consumer=consumer\n",
    "        #From: http://stackoverflow.com/questions/31047163/with-bottledwater-pg-how-to-read-data-by-a-python-consumer/31085531#31085531\n",
    "        single_message_sent=False\n",
    "        print 'waiting'\n",
    "        time.sleep(1)\n",
    "        #TODO: CREATE TEST TO MAKE SURE THE TOPIC EXISTS IN THE PARTITION\n",
    "        print consumer.partitions_for_topic('sink1')\n",
    "        for msg in consumer:\n",
    "            self.msg_num=self.msg_num+1\n",
    "            #print msg\n",
    "            if self.cancelled!=True:\n",
    "                if (time.time()%1)<(1.0/2.0):\n",
    "                    try:\n",
    "                        #print msg, time.time()\n",
    "                        self.decode_message(msg)\n",
    "                    except:\n",
    "                        print \"Unexpected error:\", sys.exc_info()[0]\n",
    "                        print 'Message not able to be sent:',msg\n",
    "                        single_message_sent=False\n",
    "                    #send a message the first time this loop is run\n",
    "                    if single_message_sent!=True:\n",
    "                        print 'Messages are now being sent to a Carbon-Whisper-Graphite server'\n",
    "                        single_message_sent=True\n",
    "            else:\n",
    "                print 'exiting consumer loop'\n",
    "                break\n",
    "            \n",
    "    def decode_message(self,msg):\n",
    "        #get the value of the message\n",
    "        try:\n",
    "            datum=msg.value #THIS IS FOR THE KAFKA STRUCTURE\n",
    "            #convert the csv to an array\n",
    "            datum_array = datum.split(\",\")\n",
    "        except:\n",
    "            print 'unable to get message'\n",
    "            datum_array=msg #THIS IS FOR THE SYNTHETIC STRUCTURE\n",
    "        #print datum_array\n",
    "        #call function to send the datum to carbon/graphite (each time send the old base topic)\n",
    "        self.add_consumer_message_to_carbon_queue(datum_array,self.topic)\n",
    "        self.add_to_history(datum_array)\n",
    "        #check how much time has passed, and if yes, send to grafana\n",
    "        if (time.time()-1) > self.last_send_time:\n",
    "            self.send_message_to_carbon()\n",
    "            #reset the empty data array which is sent to send batch messages to carbon\n",
    "            self.data=[]\n",
    "    \n",
    "    def send_message_to_carbon(self):\n",
    "        #send the batch data array\n",
    "        self.carbon.send_data(self.data)\n",
    "        self.last_send_time=time.time()\n",
    "        print 'messages sent to carbon',time.time()\n",
    "        #print self.data\n",
    "        \n",
    "        #print 'data sent to consumer at',time.time()\n",
    "        \n",
    "        #print self.data\n",
    "        #self.cancel()\n",
    "        #kill the thread so it only runs once\n",
    "        \n",
    "    def setup_history(self):\n",
    "        rois=self.channel_schema[1:-2] #avoid columns with sensor and time\n",
    "        len_history=100\n",
    "        columns=['time'] #first column\n",
    "        second_column=['sensor_type']\n",
    "        sensor_types=['AF3','AF4','T7','T8','Pz']\n",
    "        for roi in rois:\n",
    "            columns.append(roi)\n",
    "        #create a history dataframe that contains the time as well as the motion information from the different ROIs\n",
    "        self.history = pd.DataFrame.from_records(np.zeros((len_history,2+len(rois)),\n",
    "                                    index=np.arange(len_history),\n",
    "                                    columns=columns))\n",
    "                                        \n",
    "    def add_to_history(self,datum_array):\n",
    "        value=[datum_array[-1],datum_array[0]]\n",
    "        for i in range(1,len(datum_array)-1):\n",
    "            value.append(datum_array[i])\n",
    "        print value\n",
    "        self.history.iloc[self.msg_num % self.history.shape[0]] = value  # set the new value in the ring buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flag=False\n",
    "p_consumer = PythonConsumerThread(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_consumer.cancel()\n",
    "#7:55:00 to 755:30 relaxed\n",
    "#758:03 758:18 blinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from kafka import TopicPartition, KafkaConsumer\n",
    "consumer = KafkaConsumer(bootstrap_servers='ec2-54-213-9-89.us-west-2.compute.amazonaws.com:9092')\n",
    "#print consumer.topics()\n",
    "#consumer.assign([TopicPartition('sink1', 1)])\n",
    "#print consumer\n",
    "#msg = next(consumer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time.time()%1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
